{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\valib\\\\OneDrive\\\\Desktop\\\\My projects\\\\Medical-Chatbot\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\valib\\\\OneDrive\\\\Desktop\\\\My projects\\\\Medical-Chatbot'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract Data From the PDF File\n",
    "def load_pdf_file(data):\n",
    "    loader= DirectoryLoader(data,\n",
    "                            glob=\"*.pdf\",\n",
    "                            loader_cls=PyPDFLoader)\n",
    "\n",
    "    documents=loader.load()\n",
    "\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data=load_pdf_file(data='Data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the Data into Text Chunks\n",
    "def text_split(extracted_data):\n",
    "    text_splitter=RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)\n",
    "    text_chunks=text_splitter.split_documents(extracted_data)\n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Text Chunks 5860\n"
     ]
    }
   ],
   "source": [
    "text_chunks=text_split(extracted_data)\n",
    "print(\"Length of Text Chunks\", len(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download the Embeddings from Hugging Face\n",
    "def download_hugging_face_embeddings():\n",
    "    embeddings=HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valib\\AppData\\Local\\Temp\\ipykernel_15528\\2661704553.py:3: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings=HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
      "c:\\Users\\valib\\anaconda3\\envs\\medibot\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "embeddings = download_hugging_face_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length 384\n"
     ]
    }
   ],
   "source": [
    "query_result = embeddings.embed_query(\"Hello world\")\n",
    "print(\"Length\", len(query_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#query_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY=os.environ.get('PINECONE_API_KEY')\n",
    "GROQ_API_KEY=os.environ.get('GROQ_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone.grpc import PineconeGRPC as Pinecone\n",
    "from pinecone import ServerlessSpec\n",
    "import os\n",
    "\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "index_name = \"medicalbot-final\"\n",
    "\n",
    "pc.create_index(\n",
    "    name=index_name,\n",
    "    dimension=384, \n",
    "    metric=\"cosine\", \n",
    "    spec=ServerlessSpec(\n",
    "        cloud=\"aws\", \n",
    "        region=\"us-east-1\"\n",
    "    ) \n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "print(GROQ_API_KEY)  # This should print the API key, not 'None'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PINECONE_API_KEY\"] = PINECONE_API_KEY\n",
    "os.environ[\"GROQ_API_KEY\"] = GROQ_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed each chunk and upsert the embeddings into your Pinecone index.\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "docsearch = PineconeVectorStore.from_documents(\n",
    "    documents=text_chunks,\n",
    "    index_name=index_name,\n",
    "    embedding=embeddings, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_pinecone.vectorstores.PineconeVectorStore at 0x20ad8db0b90>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = docsearch.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs = retriever.invoke(\"What is Acne?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='834667b7-ff3c-4684-b9b3-7033797104a7', metadata={'creationdate': '2004-12-18T17:00:02-05:00', 'creator': 'PyPDF', 'moddate': '2004-12-18T16:15:31-06:00', 'page': 39.0, 'page_label': '40', 'producer': 'PDFlib+PDI 5.0.0 (SunOS)', 'source': 'Data\\\\Medical_book.pdf', 'total_pages': 637.0}, page_content='GALE ENCYCLOPEDIA OF MEDICINE 226\\nAcne\\nGEM - 0001 to 0432 - A  10/22/03 1:41 PM  Page 26'),\n",
       " Document(id='604cc982-6eb6-4e87-b114-86465a91fb38', metadata={'creationdate': '2004-12-18T17:00:02-05:00', 'creator': 'PyPDF', 'moddate': '2004-12-18T16:15:31-06:00', 'page': 38.0, 'page_label': '39', 'producer': 'PDFlib+PDI 5.0.0 (SunOS)', 'source': 'Data\\\\Medical_book.pdf', 'total_pages': 637.0}, page_content='GALE ENCYCLOPEDIA OF MEDICINE 2 25\\nAcne\\nAcne vulgaris affecting a womanâ€™s face. Acne is the general\\nname given to a skin disorder in which the sebaceous\\nglands become inflamed.(Photograph by Biophoto Associ-\\nates, Photo Researchers, Inc. Reproduced by permission.)\\nGEM - 0001 to 0432 - A  10/22/03 1:41 PM  Page 25'),\n",
       " Document(id='ec5a5af6-a769-4326-b0c4-8d17363d895c', metadata={'creationdate': '2004-12-18T17:00:02-05:00', 'creator': 'PyPDF', 'moddate': '2004-12-18T16:15:31-06:00', 'page': 37.0, 'page_label': '38', 'producer': 'PDFlib+PDI 5.0.0 (SunOS)', 'source': 'Data\\\\Medical_book.pdf', 'total_pages': 637.0}, page_content='Acidosis see Respiratory acidosis; Renal\\ntubular acidosis; Metabolic acidosis\\nAcne\\nDefinition\\nAcne is a common skin disease characterized by\\npimples on the face, chest, and back. It occurs when the\\npores of the skin become clogged with oil, dead skin\\ncells, and bacteria.\\nDescription\\nAcne vulgaris, the medical term for common acne, is\\nthe most common skin disease. It affects nearly 17 million\\npeople in the United States. While acne can arise at any')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fast language models are crucial in modern natural language processing (NLP) as they enable efficient and effective processing of human language. Here are some key reasons why fast language models are important:\n",
      "\n",
      "1. **Real-time Applications**: Fast language models can handle real-time applications such as chatbots, virtual assistants, and voice-activated devices. They can quickly process and respond to user input, creating a seamless user experience.\n",
      "2. **Large-Scale Text Analysis**: Fast language models can process vast amounts of text data quickly, making them ideal for large-scale text analysis tasks such as sentiment analysis, entity recognition, and topic modeling.\n",
      "3. **Improved User Engagement**: Fast language models can enhance user engagement by providing quick and accurate responses to user queries. This is particularly important in applications such as customer service, where timely responses can significantly impact user satisfaction.\n",
      "4. **Competitive Advantage**: Organizations that utilize fast language models can gain a competitive advantage by processing and analyzing large amounts of text data quickly, enabling them to make informed decisions and respond to market trends faster.\n",
      "5. **Cost Savings**: Fast language models can help reduce computational costs by processing text data more efficiently. This can lead to significant cost savings, particularly in cloud-based environments where computational resources are billed by the hour.\n",
      "6. **Scalability**: Fast language models can handle large volumes of text data and scale to meet the needs of growing applications, making them ideal for applications with high traffic or data-intensive workloads.\n",
      "7. **Improved Accuracy**: Fast language models can also lead to improved accuracy in NLP tasks. By quickly processing and analyzing large amounts of text data, these models can learn from more data, leading to better performance and accuracy.\n",
      "8. **Multilingual Support**: Fast language models can be fine-tuned to support multiple languages, making them ideal for applications that require multilingual support, such as language translation, sentiment analysis, and text classification.\n",
      "\n",
      "Some of the applications that benefit from fast language models include:\n",
      "\n",
      "1. **Virtual assistants**: Fast language models enable virtual assistants like Siri, Alexa, and Google Assistant to quickly process and respond to user queries.\n",
      "2. **Chatbots**: Fast language models power chatbots, enabling them to quickly respond to user input and provide accurate information.\n",
      "3. **Sentiment analysis**: Fast language models can quickly process large amounts of text data to analyze sentiment, helping organizations understand customer opinions and preferences.\n",
      "4. **Language translation**: Fast language models can quickly translate text from one language to another, enabling real-time communication across languages.\n",
      "5. **Text summarization**: Fast language models can quickly summarize large documents, providing a concise and accurate summary of the content.\n",
      "\n",
      "In summary, fast language models are essential in modern NLP as they enable efficient and effective processing of human language, leading to improved user engagement, competitive advantage, cost savings, and scalability.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from groq import Groq\n",
    "\n",
    "client = Groq(\n",
    "    api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Explain the importance of fast language models\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='There have been many recent advancements in Artificial Intelligence (AI), and it\\'s difficult to pinpoint a single \"latest\" one. However, here are some of the most significant developments in the field:\\n\\n1. **AlphaFold**: In 2020, Google\\'s DeepMind AI system, AlphaFold, was able to predict the 3D structure of proteins with unprecedented accuracy. This breakthrough has the potential to revolutionize our understanding of biology and medicine.\\n2. **Transformers**: The Transformer architecture, introduced in 2017, has become a standard component in many AI systems. It\\'s particularly effective for natural language processing tasks, such as language translation, text summarization, and chatbots.\\n3. **Generative Adversarial Networks (GANs)**: GANs have made significant progress in generating realistic images, videos, and music. They\\'re being used in applications like data augmentation, image synthesis, and style transfer.\\n4. **Explainable AI (XAI)**: As AI systems become more pervasive, there\\'s a growing need to understand how they make decisions. XAI aims to provide transparent and interpretable explanations for AI outputs, improving trust and accountability.\\n5. **Edge AI**: With the proliferation of IoT devices, Edge AI is becoming increasingly important. It enables AI processing to occur closer to the data source, reducing latency and improving real-time decision-making.\\n6. **Multimodal AI**: Researchers have made significant progress in developing AI systems that can process and integrate multiple forms of data, such as text, images, and audio. This has applications in areas like customer service, healthcare, and autonomous vehicles.\\n7. **Reinforcement Learning (RL)**: RL has seen significant advancements, enabling AI agents to learn from trial and error in complex environments. This has applications in areas like robotics, game playing, and autonomous systems.\\n8. **Neural Architecture Search (NAS)**: NAS is a technique that automates the design of AI models, allowing for faster development and improvement of AI systems.\\n9. **Quantum AI**: The intersection of quantum computing and AI is an emerging field, with potential applications in areas like optimization, cryptography, and machine learning.\\n10. **Human-AI Collaboration**: As AI becomes more prevalent, there\\'s a growing focus on designing systems that collaborate with humans, rather than replacing them. This requires developing AI systems that can understand human behavior, emotions, and decision-making processes.\\n\\nThese are just a few examples of the many' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 500, 'prompt_tokens': 18, 'total_tokens': 518, 'completion_time': 0.416666667, 'prompt_time': 0.002571462, 'queue_time': 0.23490592500000002, 'total_time': 0.419238129}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_a97cfe35ae', 'finish_reason': 'length', 'logprobs': None} id='run-d3598b5f-b562-49f8-9401-b51fbd7c6727-0' usage_metadata={'input_tokens': 18, 'output_tokens': 500, 'total_tokens': 518}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "# Set the API key manually\n",
    "os.environ[\"GROQ_API_KEY\"] = \"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\"\n",
    "\n",
    "# Initialize the Groq LLM\n",
    "llm = ChatGroq(\n",
    "    model_name=\"llama3-8b-8192\",  # or \"llama3-70b-8192\"\n",
    "    temperature=0.4,\n",
    "    max_tokens=500,\n",
    "    api_key=os.getenv(\"GROQ_API_KEY\")  # Fetching API key\n",
    ")\n",
    "\n",
    "# Example Query\n",
    "response = llm.invoke(\"What is the latest advancement in AI?\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import os\n",
    "\n",
    "# Set Groq API Key (Ensure you have set it in environment variables)\n",
    "os.environ[\"GROQ_API_KEY\"] = \"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\"\n",
    "\n",
    "# Define System Prompt\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "# Define Chat Prompt Template\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Initialize Groq LLM\n",
    "llm = ChatGroq(\n",
    "    model_name=\"llama3-8b-8192\",  # or \"llama3-70b-8192\"\n",
    "    temperature=0.4,\n",
    "    max_tokens=500,\n",
    "    api_key=os.getenv(\"GROQ_API_KEY\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acromegaly is a disorder in which the abnormal release of a particular chemical from the pituitary gland in the brain causes increased growth in bone and soft tissue, as well as a variety of other disturbances throughout the body. Gigantism is a similar condition, but it occurs when the abnormality occurs before bone growth stops, resulting in unusual height.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"what is Acromegaly and gigantism?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't know. The context provided doesn't mention \"stats\". It appears to be discussing a blood count test and athletic heart syndrome.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"What is stats?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medibot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
